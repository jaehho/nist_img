{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Red Line Detection and Tracking in Video\n",
    "\n",
    "This notebook detects and tracks the intersection of the red lines in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import requests\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Load and Prepare Video\n",
    "\n",
    "`cap` defines the video source, which can be a file path or a camera index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "os.makedirs('tmp', exist_ok=True)\n",
    "video_path = 'tmp/shake.mp4'\n",
    "url = 'https://nist-assets.s3.us-east-1.amazonaws.com/shake.mp4'\n",
    "with open(video_path, 'wb') as f:\n",
    "    f.write(requests.get(url).content)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Guide Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "num_ref_frames = 10\n",
    "frame_indices = [int(i * frame_count / num_ref_frames) for i in range(num_ref_frames)]\n",
    "\n",
    "all_frames, selected_frames = [], []\n",
    "for idx in tqdm(range(frame_count), desc='Loading frames'):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    rotated = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "    frame_rgb = cv2.cvtColor(rotated, cv2.COLOR_BGR2RGB)\n",
    "    all_frames.append(frame_rgb)\n",
    "    if idx in frame_indices:\n",
    "        selected_frames.append(frame_rgb)\n",
    "cap.release()\n",
    "\n",
    "def plot_frames(frames, titles):\n",
    "    fig, axes = plt.subplots(1, len(frames), figsize=(20, 4))\n",
    "    for ax, frame, title in zip(axes, frames, titles):\n",
    "        ax.imshow(frame)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(title)\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "\n",
    "plot_frames(selected_frames, [f'Frame {idx}\\n{idx / fps:.2f}s' for idx in frame_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Select Guide Frame\n",
    "\n",
    "`guide_frame_idx` defines the frame to use as a reference for per frame image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_frame_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_frame = all_frames[guide_frame_idx]\n",
    "frame_hsv = cv2.cvtColor(guide_frame.copy(), cv2.COLOR_RGB2HSV)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.imshow(guide_frame)\n",
    "ax.axis('off')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Define HSV Hue Range for Red Detection\n",
    "\n",
    "`start_hue` and `end_hue` define the red hue range.\n",
    "`s_min` and `s_max` define the saturation range.\n",
    "`v_min` and `v_max` define the value/brightness range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_hue, end_hue = 145, (145 + 45) % 180\n",
    "s_min, s_max = 100, 255\n",
    "v_min, v_max = 100, 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def show_hue_range(start, end, s_min=100, s_max=255, v_min=100, v_max=255, axes=None):\n",
    "    height, width = 100, 180\n",
    "    h = np.linspace(0, 179, width, dtype=np.uint8)\n",
    "    s = np.full(height, s_max, dtype=np.uint8)\n",
    "    v = np.full(height, v_max, dtype=np.uint8)\n",
    "    hsv_img = np.stack([np.tile(h, (height, 1)),\n",
    "                        np.tile(s[:, None], (1, width)),\n",
    "                        np.tile(v[:, None], (1, width))], axis=-1).astype(np.uint8)\n",
    "\n",
    "    if start < end:\n",
    "        lower, upper = np.array([start, s_min, v_min]), np.array([end, s_max, v_max])\n",
    "        mask = cv2.inRange(hsv_img, lower, upper)\n",
    "        bounds = [[lower, upper]]\n",
    "    else:\n",
    "        mask1 = cv2.inRange(hsv_img, np.array([start, s_min, v_min]), np.array([179, s_max, v_max]))\n",
    "        mask2 = cv2.inRange(hsv_img, np.array([0, s_min, v_min]), np.array([end, s_max, v_max]))\n",
    "        mask = cv2.bitwise_or(mask1, mask2)\n",
    "        bounds = [[np.array([start, s_min, v_min]), np.array([179, s_max, v_max])],\n",
    "                  [np.array([0, s_min, v_min]), np.array([end, s_max, v_max])]]\n",
    "\n",
    "    rgb_img = cv2.cvtColor(hsv_img, cv2.COLOR_HSV2RGB)\n",
    "    result = cv2.bitwise_and(rgb_img, rgb_img, mask=mask)\n",
    "\n",
    "    for i, img in enumerate([rgb_img, mask, result]):\n",
    "        axes[i].imshow(img if i != 1 else img, cmap='gray' if i == 1 else None)\n",
    "        axes[i].set_yticks([]); axes[i].set_xticks([0, 45, 90, 135, 180])\n",
    "\n",
    "    return bounds\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(15, 4), sharex=True)\n",
    "hue_range = show_hue_range(start=start_hue, end=end_hue, \n",
    "                           s_min=s_min, s_max=s_max, \n",
    "                           v_min=v_min, v_max=v_max, \n",
    "                           axes=ax)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Line Detection Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_red_mask(hsv_img, bounds):\n",
    "    masks = [cv2.inRange(hsv_img, lower, upper) for lower, upper in bounds]\n",
    "    return cv2.bitwise_or(*masks)\n",
    "\n",
    "def draw_fitted_line(img, params, color, length=4000, thickness=8):\n",
    "    if params is None: return\n",
    "    vx, vy, x0, y0 = params\n",
    "    pt1 = (int(x0 - length * vx), int(y0 - length * vy))\n",
    "    pt2 = (int(x0 + length * vx), int(y0 + length * vy))\n",
    "    cv2.line(img, pt1, pt2, color, thickness)\n",
    "\n",
    "def separate_lines(lines):\n",
    "    horiz, vert = [], []\n",
    "    for [[x1, y1, x2, y2]] in lines:\n",
    "        angle = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi\n",
    "        (horiz if -20 < angle < 20 else vert if 70 < abs(angle) < 110 else []).append((x1, y1, x2, y2))\n",
    "    return horiz, vert\n",
    "\n",
    "def fit_line(lines):\n",
    "    if not lines: return None\n",
    "    pts = np.array([[[x, y]] for line in lines for x, y in [line[:2], line[2:]]])\n",
    "    return cv2.fitLine(pts, cv2.DIST_L2, 0, 0.01, 0.01).flatten()\n",
    "\n",
    "def compute_intersection(v1, v2):\n",
    "    try:\n",
    "        A = np.array([[v1[0], -v2[0]], [v1[1], -v2[1]]])\n",
    "        b = np.array([v2[2] - v1[2], v2[3] - v1[3]])\n",
    "        t, _ = np.linalg.solve(A, b)\n",
    "        return int(v1[2] + t * v1[0]), int(v1[3] + t * v1[1])\n",
    "    except np.linalg.LinAlgError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Process Video Frames and Track Red Line Intersections\n",
    "\n",
    "`gaussian_kernel_size` controls the Gaussian blur applied to the red mask.\n",
    "`canny_threshold1` and `canny_threshold2` control the Canny edge detection sensitivity.\n",
    "`hough_threshold` is the threshold for Hough line detection.\n",
    "`hough_min_line_length` and `hough_max_line_gap` control the minimum line length and maximum gap for Hough line detection.\n",
    "\n",
    "After processing the frames, frames with less than 1% of \"red\" pixels are skipped assuming there is not laser present. Any frames with detected lines but no intersection are assumed to have failed in processing are displayed for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_kernel_size = (101, 101)\n",
    "canny_threshold1 = 5\n",
    "canny_threshold2 = 30\n",
    "\n",
    "hough_threshold = 30\n",
    "hough_minLineLength = 500\n",
    "hough_maxLineGap = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = all_frames[0].shape[:2]\n",
    "video_out = cv2.VideoWriter('tmp/output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
    "\n",
    "intersection_points, skipped_frames, failing_frames = [], [], []\n",
    "red_pixel_percentages = []\n",
    "\n",
    "for i, frame_rgb in tqdm(enumerate(all_frames), total=len(all_frames), desc=\"Processing frames\"):\n",
    "    hsv = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2HSV)\n",
    "    red_mask = get_red_mask(hsv, hue_range)\n",
    "    red_pct = 100 * cv2.countNonZero(red_mask) / (h * w)\n",
    "    red_pixel_percentages.append(red_pct)\n",
    "\n",
    "    if red_pct < 1.0:\n",
    "        intersection_points.append(None)\n",
    "        skipped_frames.append(i)\n",
    "        video_out.write(cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR))\n",
    "        continue\n",
    "\n",
    "    blurred = cv2.GaussianBlur(red_mask, gaussian_kernel_size, sigmaX=0)\n",
    "    edges = cv2.Canny(blurred, canny_threshold1, canny_threshold2)\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, hough_threshold, minLineLength=hough_minLineLength, maxLineGap=hough_maxLineGap)\n",
    "\n",
    "    horiz, vert = separate_lines(lines) if lines is not None else ([], [])\n",
    "    fitted_h, fitted_v = fit_line(horiz), fit_line(vert)\n",
    "    inter_pt = compute_intersection(fitted_h, fitted_v) if (fitted_h is not None and fitted_v is not None) else None\n",
    "\n",
    "    if inter_pt is None and red_pct >= 1.0:\n",
    "        failing_frames.append(i)\n",
    "\n",
    "    intersection_points.append(inter_pt)\n",
    "    annotated = frame_rgb.copy()\n",
    "    draw_fitted_line(annotated, fitted_h, (0, 255, 0))\n",
    "    draw_fitted_line(annotated, fitted_v, (0, 255, 0))\n",
    "    if inter_pt: cv2.circle(annotated, inter_pt, 15, (0, 0, 255), -1)\n",
    "    video_out.write(cv2.cvtColor(annotated, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    if i == guide_frame_idx:\n",
    "        frame_lines_overlay = frame_rgb.copy()\n",
    "        if lines is not None:\n",
    "            for line in lines:\n",
    "                x1, y1, x2, y2 = line[0]\n",
    "                cv2.line(frame_lines_overlay, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(20, 20))\n",
    "        axes[0, 0].imshow(frame_rgb)\n",
    "        axes[0, 0].axis('off')\n",
    "        axes[0, 0].set_title('Original Frame')\n",
    "        \n",
    "        axes[0, 1].imshow(red_mask, cmap='gray')\n",
    "        axes[0, 1].axis('off')\n",
    "        axes[0, 1].set_title('Red Mask')\n",
    "        \n",
    "        axes[0, 2].imshow(blurred, cmap='gray')\n",
    "        axes[0, 2].axis('off')\n",
    "        axes[0, 2].set_title('Blurred Mask')\n",
    "        \n",
    "        axes[1, 0].imshow(edges, cmap='gray')\n",
    "        axes[1, 0].axis('off')\n",
    "        axes[1, 0].set_title('Canny Edges')\n",
    "        \n",
    "        axes[1, 1].imshow(frame_lines_overlay)\n",
    "        axes[1, 1].axis('off')\n",
    "        axes[1, 1].set_title('Detected Lines')\n",
    "        \n",
    "        axes[1, 2].imshow(annotated)\n",
    "        axes[1, 2].axis('off')\n",
    "        axes[1, 2].set_title('Annotated Frame')\n",
    "        \n",
    "        fig.tight_layout()\n",
    "\n",
    "video_out.release()\n",
    "print(f\"Processed {len(intersection_points)} frames. Skipped: {len(skipped_frames)}, Failed: {len(failing_frames)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Visualize Failing Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if failing_frames:\n",
    "    rows, cols = -(-len(failing_frames) // 4), min(len(failing_frames), 4)\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 10 * rows))\n",
    "    axes = axes.flatten() if rows > 1 else [axes]\n",
    "    for ax, idx in zip(axes, failing_frames):\n",
    "        ax.imshow(all_frames[idx])\n",
    "        ax.set_title(f\"Frame {idx}\")\n",
    "        ax.axis('off')\n",
    "    for ax in axes[len(failing_frames):]: ax.axis('off')\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"All frames have valid intersections.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Plot Intersection Path Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = [(i, pt) for i, pt in enumerate(intersection_points) if pt]\n",
    "indices, pts = zip(*valid)\n",
    "x_vals, y_vals = zip(*pts)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "ax.imshow(all_frames[-1])\n",
    "ax.scatter(x_vals, y_vals, c='red')\n",
    "\n",
    "for i in range(len(indices) - 1):\n",
    "    if indices[i+1] == indices[i] + 1:\n",
    "        ax.plot([x_vals[i], x_vals[i+1]], [y_vals[i], y_vals[i+1]], c='blue')\n",
    "\n",
    "ax.axis('off')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
